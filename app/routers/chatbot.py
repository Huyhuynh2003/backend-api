from fastapi import APIRouter
from pydantic import BaseModel
import chromadb
from sentence_transformers import SentenceTransformer
from openai import OpenAI
import os

# ======================
# OpenAI client
# ======================
OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    raise RuntimeError("Missing OPENAI_API_KEY environment variable!")

client = OpenAI(api_key=OPENAI_API_KEY)

# ======================
# Router
# ======================
router = APIRouter(prefix="/api/chatbot", tags=["Chatbot"])

# ======================
# LAZY GLOBAL VARIABLES
# ======================
chroma_client = None
collection = None
embed_model = None

# ======================
# INIT FUNCTION
# ======================
def init_rag():
    global chroma_client, collection, embed_model

    if chroma_client is None:
        chroma_client = chromadb.PersistentClient(
            path="app/AI/vector_db"
        )

    if collection is None:
        collection = chroma_client.get_collection("medical_rag")

    if embed_model is None:
        embed_model = SentenceTransformer("BAAI/bge-small-en")

# ======================
# PROMPT
# ======================
SYSTEM_PROMPT = """
Báº¡n lÃ  trá»£ lÃ½ y táº¿ an toÃ n, chá»‰ há»— trá»£ cÃ¡c váº¥n Ä‘á» liÃªn quan Ä‘áº¿n sá»©c khá»e vÃ  y táº¿.

QUY Táº®C:
- Chá»‰ tráº£ lá»i cÃ¡c cÃ¢u há»i thuá»™c lÄ©nh vá»±c y táº¿, triá»‡u chá»©ng, bá»‡nh, chÄƒm sÃ³c sá»©c khá»e, sÆ¡ cá»©u, hÆ°á»›ng dáº«n an toÃ n.
- Náº¿u cÃ¢u há»i KHÃ”NG liÃªn quan Ä‘áº¿n y táº¿ -> pháº£i tráº£ lá»i:
  "TÃ´i chá»‰ há»— trá»£ cÃ¡c cÃ¢u há»i liÃªn quan Ä‘áº¿n sá»©c khá»e vÃ  y táº¿."
- Æ¯u tiÃªn dÃ¹ng dá»¯ liá»‡u tá»« RAG.
- KHÃ”NG cháº©n Ä‘oÃ¡n bá»‡nh.
- KHÃ”NG kÃª thuá»‘c.
- Náº¿u triá»‡u chá»©ng nguy hiá»ƒm -> yÃªu cáº§u Ä‘áº¿n bá»‡nh viá»‡n.
"""

class UserMessage(BaseModel):
    message: str

# ======================
# RAG RETRIEVAL
# ======================
def retrieve_context(query: str):
    init_rag()  # ğŸ”¥ LOAD Táº I ÄÃ‚Y

    query_vec = embed_model.encode([query]).tolist()

    result = collection.query(
        query_embeddings=query_vec,
        n_results=3
    )

    docs = result.get("documents", [[]])[0]
    return "\n\n".join(docs)

# ======================
# API
# ======================
@router.post("")
async def chatbot(msg: UserMessage):
    user_input = msg.message

    # ğŸ”¹ Láº¥y dá»¯ liá»‡u RAG
    context = retrieve_context(user_input)

    # ğŸ”¹ Náº¿u RAG rá»—ng
    if context.strip() == "":
        return {
            "reply": "TÃ´i chá»‰ há»— trá»£ cÃ¡c cÃ¢u há»i liÃªn quan Ä‘áº¿n sá»©c khá»e vÃ  y táº¿."
        }

    # ğŸ”¹ Káº¿t há»£p SYSTEM_PROMPT + context + cÃ¢u há»i
    prompt = f"""
{SYSTEM_PROMPT}

Dá»¯ liá»‡u RAG:
{context}

CÃ¢u há»i:
{user_input}
"""

    # ğŸ”¹ Gá»i OpenAI API
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.2
    )

    return {"reply": response.choices[0].message.content}
